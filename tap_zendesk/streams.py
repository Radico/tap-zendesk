import pendulum

import singer

from .schemas import IDS

logger = singer.get_logger()


def metrics(tap_stream_id, records):
    with singer.metrics.record_counter(tap_stream_id) as counter:
        counter.increment(len(records))


def write_records(tap_stream_id, records):
    singer.write_records(tap_stream_id, records)
    metrics(tap_stream_id, records)


class BOOK(object):
    USERS = [IDS.USERS, 'updated_at']
    TICKETS = [IDS.TICKETS, 'updated_at']
    SATISFACTION_RATINGS = [IDS.SATISFACTION_RATINGS, 'updated_at']
    TICKET_EVENTS = [IDS.TICKET_EVENTS, 'updated_at']
    TICKET_METRIC_EVENTS =[IDS.TICKET_METRIC_EVENTS, 'updated_ad']
    CHATS = [IDS.CHATS, 'updated_at']

    @classmethod
    def return_bookmark_path(cls, stream):
        return getattr(cls, stream.upper())

    @classmethod
    def get_incremental_syncs(cls):
        syncs = []
        for k, v in cls.__dict__.items():
            if not k.startswith("__") and not isinstance(v, classmethod):
                if len(v) > 1:
                    syncs.append(k)

        return syncs

    @classmethod
    def get_full_syncs(cls):
        syncs = []
        for k, v in cls.__dict__.items():
            if not k.startswith("__") and not isinstance(v, classmethod):
                if len(v) == 1:
                    syncs.append(k)

        return syncs


def sync(context):
    for stream in context.selected_stream_ids:
        if stream.upper() in BOOK.get_incremental_syncs():
            bk = call_stream_incremental(context, stream)
            save_state(context, stream, bk)


def call_stream_incremental(ctx, stream):
    ctx.update_start_date_bookmark(BOOK.return_bookmark_path(stream))
    last_updated = ctx.get_bookmark(BOOK.return_bookmark_path(stream))

    #  chats uses a new zopim endpoint versus the legacy zendesk.com endpoint
    if stream == 'chats':
        state_to_save = call_zopim_stream(ctx, stream, last_updated)

    else:
        state_to_save = call_legacy_stream(ctx, stream, last_updated)
    
    return state_to_save


def call_legacy_stream(ctx, stream, last_updated):
    params = {"start_time": pendulum.parse(last_updated).int_timestamp}

    while True:
        logger.info("Extracting {s} since {ts}".format(
            s=stream,
            ts=timestamp_to_iso8601(params['start_time'])
        ))

        res = ctx.client.GET(stream, params, stream)

        write_records(stream, res.get(stream))

        if res['count'] == 1000:
            # returns max 1000, if less than 1000 then end of records
            # https://developer.zendesk.com/rest_api/docs/core/incremental_export#pagination
            params['start_time'] = res['end_time']

        else:
            break

    return get_state_to_save(res, last_updated)


def call_zopim_stream(ctx, stream, last_updated):
    start_time = last_updated
    logger.info("Extracting {stream} since {start_time}".format(
        stream=stream,
        start_time=start_time
    ))

    start_time_param = 'timestamp:[{start_time} TO *]'.format(
        start_time=start_time
    )
    params = {'q': start_time_param}

    while True:
        #  first fetch list of incremental chat IDs
        ids, next_url = fetch_chat_ids(ctx, stream, params)
        most_recent_chat = max(id.get('timestamp') for id in ids)
        earliest_chat = min(id.get('timestamp') for id in ids)

        if pendulum.parse(most_recent_chat) > pendulum.parse(last_updated):
            last_updated = most_recent_chat

        #  then make bulk requests for additional fields
        detailed_results = fetch_chat_detail(ctx, stream, ids)
        write_records(stream, detailed_results)

        if next_url:
            #  paginating results generated by fetch_chat_ids
            page_param = next_url.split('page=')[-1]
            #  api stops at 250 pages so need to check for addtl data
            if page_param == '251':
                start_time_param = 'timestamp:[{start_time} TO {end_time}]'.format(
                    start_time=start_time,
                    end_time=earliest_chat
                )
                params = {'q': start_time_param}
            else:
                params['page']= page_param

        else:
            break

    return get_state_to_save(res={}, last_updated=last_updated)


def fetch_chat_ids(ctx, stream, params):
    res = ctx.client.GET(stream, params, stream)
    ids = res.get('results')
    next_url = res.get('next_url') if 'next_url' in res else None
    return ids, next_url


def fetch_chat_detail(ctx, stream, ids):
    ids = list(map(lambda result: result.get('id'), ids))
    detailed_results = []

    #  can only request 50 chats at a time via bulk api
    max_batch_size = 50
    len_ids = len(ids)
    pointer = 0

    while pointer <= len_ids:
        start = pointer
        end = pointer + max_batch_size \
            if pointer + max_batch_size < len_ids \
            else len_ids
        batch_of_ids = ids[start:end]
        logger.info('Fetching {n} chat details:'.format(n=len(batch_of_ids)))
        comma_sep_ids = ",".join(batch_of_ids)

        params = {'ids': comma_sep_ids}
        res = ctx.client.GET(stream, params, stream)

        chat_details = res.get('docs')
        for id in batch_of_ids:
            detailed_results.append(chat_details[id])

        pointer = pointer + max_batch_size
    
    return detailed_results


def get_state_to_save(res, last_updated):
    if res.get('end_time'):
        return timestamp_to_iso8601(res['end_time'])
    else:
        return last_updated


def timestamp_to_iso8601(ts):
    return pendulum.from_timestamp(int(ts)).to_iso8601_string()


def save_state(context, stream, bk):
    context.set_bookmark(BOOK.return_bookmark_path(stream), bk)
    context.write_state()
